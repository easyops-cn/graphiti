# 23. 实体类型打分优化 - Top 3 候选 + 二次推理

## 问题背景

原有的实体类型打分机制要求 LLM 对**所有**实体类型进行打分，存在以下问题：

1. **Token 消耗过大**：如果有 10 个实体类型，每个实体需要输出 10 组 (type_id, score, reasoning)
2. **效率低下**：大部分类型的分数都很低，没有必要输出
3. **歧义处理不足**：当多个类型都有较高分数时，缺乏进一步判断机制

## 解决方案

采用**两阶段类型分类**策略：

### 阶段 1：Top 3 候选打分

只输出最可能的 3 个类型候选，每个候选包含分数和推理说明。

**修改文件**：`graphiti_core/prompts/extract_nodes.py`

```python
class TopTypeCandidate(BaseModel):
    """Top candidate type with score and reasoning."""
    type_id: int
    score: float  # 0.0 - 1.0
    reasoning: str  # 解释为什么给这个分数

class ExtractedEntityWithScores(BaseModel):
    """Entity with top 3 candidate types."""
    name: str
    top_candidates: list[TopTypeCandidate]  # 最多 3 个，按 score 降序
    final_type_id: int  # 最高分候选的 type_id
```

**提示词修改**：`extract_text_with_scores()` 和 `extract_message_with_scores()`

```python
**TYPE SCORING PROCESS**:
For each entity you extract:
1. Quickly scan ALL entity types to identify the 3 most likely candidates
2. Score each of these 3 candidates from 0.0 to 1.0
3. Provide reasoning for each score
4. Set final_type_id to the highest-scoring candidate
```

### 阶段 2：歧义消解（可选）

当多个候选的分数都 >= 0.7 时，触发二次推理：

1. 收集所有需要消解的实体
2. **批量**调用一次 LLM 进行最终分类
3. **不传入**第一轮的分数和推理，避免偏向

**新增模型**：

```python
class ResolvedEntityType(BaseModel):
    """Resolved type for an ambiguous entity."""
    name: str
    chosen_type_id: int
    reasoning: str  # 解释为什么选择这个类型

class ResolvedEntityTypes(BaseModel):
    """Batch resolution results for ambiguous entities."""
    resolutions: list[ResolvedEntityType]
```

**新增提示词**：`resolve_ambiguous_types()`

```python
def resolve_ambiguous_types(context: dict[str, Any]) -> list[Message]:
    """Resolve ambiguous entity types when multiple candidates >= 0.7.

    只提供候选类型定义，不传入第一轮的分数和推理，避免偏向。
    """
```

## 处理流程

```
Episode 写入
    │
    ▼
┌─────────────────────────────────────┐
│ 阶段 1: Top 3 候选打分               │
│ - 对每个实体输出最可能的 3 个类型      │
│ - 每个候选包含 score 和 reasoning    │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 检查歧义                             │
│ - 统计每个实体中 score >= 0.7 的候选数│
│ - 如果 > 1 且 Top1-Top2 差距 < 15%   │
│   → 标记为需要二次推理               │
│ - 如果差距 >= 15%，信任第一轮结果     │
└─────────────────────────────────────┘
    │
    ▼ (如果有歧义实体)
┌─────────────────────────────────────┐
│ 阶段 2: 批量歧义消解                  │
│ - 收集所有歧义实体                    │
│ - 一次 LLM 调用批量处理               │
│ - 只传候选类型定义，不传分数/推理      │
└─────────────────────────────────────┘
    │
    ▼
最终实体类型确定
```

## 性能优化效果

| 场景 | 优化前 | 优化后 |
|-----|-------|-------|
| 10 个实体类型 | 每实体输出 10 组打分 | 每实体输出 3 组打分 |
| Token 消耗 | ~300 tokens/实体 | ~100 tokens/实体 |
| 歧义实体 | 直接取最高分 | 仅分数接近时二次推理 |

## 阈值配置

| 阈值 | 值 | 用途 |
|-----|-----|------|
| `TYPE_CONFIDENCE_THRESHOLD` | 0.6 | 低于此分数降级为 Entity |
| `AMBIGUOUS_SCORE_THRESHOLD` | 0.7 | 高于此分数的候选参与歧义检查 |
| `AMBIGUOUS_SCORE_GAP_THRESHOLD` | 0.15 | Top1-Top2 差距 >= 此值则跳过二次推理 |

**二次推理触发条件**（2025-12-18 优化）：
- 原条件：`len(high_score_candidates) > 1`（只要有多个高分候选就触发）
- 新条件：`len(high_score_candidates) > 1 AND (top1_score - top2_score) < 0.15`
- **优化原因**：当 Top1 明显领先 Top2 时（如 90% vs 70%，差距 20%），第一轮结果已经可信，无需二次推理。二次推理可能因缺少分数信息而做出错误判断。

## 第二轮也要打分（2025-12-18 优化）

**问题**：原有的第二轮只需要"选一个"，没有打分约束。LLM 可能被某个类型的描述误导，做出比第一轮更差的判断。

**解决方案**：第二轮也采用与第一轮相同的打分机制，输出每个候选的分数和理由。

**新增模型**：
```python
class CandidateTypeScore(BaseModel):
    type_id: int
    score: float  # 0.0 - 1.0
    reasoning: str

class ResolvedEntityType(BaseModel):
    name: str
    chosen_type_id: int
    reasoning: str
    candidate_scores: list[CandidateTypeScore]  # 新增：每个候选的分数
```

**type_scores 存储格式**（保留两轮历史）：
```python
{
  "Feature": {
    "score": 0.85,           # 最终分数（第二轮）
    "reasoning": "...",      # 最终理由（第二轮）
    "pass1_score": 0.9,      # 第一轮分数
    "pass1_reasoning": "..." # 第一轮理由
  },
  "ProductModule": {
    "score": 0.75,
    "reasoning": "...",
    "pass1_score": 0.7,
    "pass1_reasoning": "..."
  }
}
```

**前端显示**：EntityDrawer 组件显示两轮分数，按分数降序排列，pass1 数据以灰色斜体显示。

## 修改文件清单

| 文件 | 修改内容 |
|-----|---------|
| `graphiti_core/prompts/extract_nodes.py` | `TopTypeCandidate` 模型（替代全量 `TypeScore`） |
| `graphiti_core/prompts/extract_nodes.py` | `ExtractedEntityWithScores` 改用 `top_candidates` |
| `graphiti_core/prompts/extract_nodes.py` | `CandidateTypeScore` 新增模型（第二轮打分） |
| `graphiti_core/prompts/extract_nodes.py` | `ResolvedEntityType` 新增 `candidate_scores` 字段 |
| `graphiti_core/prompts/extract_nodes.py` | `resolve_ambiguous_types()` 提示词增加打分要求 |
| `graphiti_core/prompts/extract_nodes.py` | `extract_text_with_scores()` Top 3 逻辑 |
| `graphiti_core/prompts/extract_nodes.py` | `extract_message_with_scores()` Top 3 逻辑 |
| `graphiti_core/utils/maintenance/node_operations.py` | 两阶段类型分类处理逻辑 |
| `graphiti_core/utils/maintenance/node_operations.py` | 第二轮保留 pass1 数据到 type_scores |
| `web/src/components/EntityDrawer/index.tsx` | 显示两轮分数（pass1_score, pass1_reasoning） |

---
